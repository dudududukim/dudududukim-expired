---
layout: post
title: d2f
subtitle : (ongoing)
tags: [project, mind]
# feature-title: Korea Univ.
feature-img: "assets/img/dark_room.jpg"
---

d2f projects that i'm planning to finish within 1 month (February) 🙂‍↔️

## 🚀 d2f (Temporary Name)
> 📆 24.01.31 ~ 

<br>
### 🛠 Tech Stack
- mlx framework
- python
- matlab
- etc...

<br>
### 🎯 Why Start This?
Since I'm unsure about what I want to be—a businessman, a startup member, a personal developer, or something else—I've been feeling uneasy these days. However, one thing I've realized is that I have a strong desire to solve my own problems or fulfill my own needs by learning new skills, such as AI, circuit design, and system development. Whether intentional or not, I have a day off today, so I'm setting aside my future plans and immersing myself in this project.

**Final goal** is : 
1. making active users with my product
2. finishing with a level of completeness that makes it presentable

Praying for myself 🧯

<br>
## 📝 Issues

#### <br>*1. mlx.data.buffer_from_vector*
**error** : dictionary로 구성된 sample = [{'image' : b'Path/'}], 

이거를 buffer_from_vector를 mlx.data로 실행하면 byte array가 넘어와야하는데, 빈배열이 넘어옴 ([] dtype=int8)

**Solution** : 

Mac 초기화 -> mlx-data를 pip로 install하지 않고 소스코드에서 python blinding으로 설치함

(환경변수와 다양한 dependency가 꼬여있던 것으로 파단됨)

#### <br>*2. mlx framework insights*
**Buffer** : image를 필요시에 load하여 불필요하게 load되는 경우를 막는다. -> 애플이 지리긴하는듯 (결국 Apple silicon을 만든이상 그들의 framework와 protocol 개발은 불가피하고, 여기서도 만약에 두각을 드러낸다면 결국 애플 사이클 다시 온다고 봄)


**stream.prefetch(4, 4)** : CPU에서 4개의 batch를 GPU연산동안 load해두고, GPU도 4개의 batch를 한번에 불러드리도록 설정함

#### <br>*3. binary cross entropy에서 mx.compile 문제*

해결 못함 ➡️ 그냥 num_classes=2 로 하고 mlx.nn.losses.cross_entropy로 함

binary cross entropy에서 @partial(mx.compile) 옵션에서 문제가 발생하는 듯함

#### <br> *4. Training overfitting (resent44)*

training data가 204개에서 training이 overfitting이 발견하는 것을 확인하였다.

데이터는 (224,224) center crop되어 사용되었고, batch_size = 16, epoch=50, lr=1e-5

| Epoch | Train Loss | Train Accuracy | Test Accuracy |
|-------|-----------|---------------|--------------|
| 49    | 0.040     | 0.990         | 0.688        |

📙 이유? 아마도 data가 부족한듯 하다. image crop까지는 어떻게 하긴하는데, crop보다는 224,224 데이터를 새로 생성해서 진행해야겠다.

#### <br> *5. 224,224로 이미지 쪼개서 학습 진행*

💾 원래 데이터 : 1.02GB -> 743MB (6.13GB disk)

train length : 42111  
Test length : 4678 

🙋🏾‍♂️ 했는데도 training acc는 1에 epoch1만에 수렴하는데, test accur는 서서히 올라가긴하나 **overfitting을** 보임

사실 내가 어떤 프로젝트를 진행하거나 공부를 진행할때 항상 이러한 넘기 귀찮은 문제들에서 포기하고 그냥 학교나 사회에서 주어진 것들을 열심히 하기 위해서 돌아갔었다.
그런데 이번 한달의 목표를 이러한 나를 마주하고 그러한 허들을 침착고 조용히 꾸준하게 넘어가려고 한다.
이번에도 사실 그냥 '아 뭐야 몰라'하고 넘어갈 수 있지만 **나는 이번만큼은 끝을 봐야한다.**

![alt text]({{site.url}}/assets/img/unbalanced_dataset.png)

보면, buffer를 랜덤하게 shuffle하고 plot을 해보았는데, **데이터의 상당한 편향**을 발견했다. 224x224는 동일하게 crop했지만 1.7x 좋아서 croppd에서 3:1 정도로 image가 많은 것을 확인했다. 데이터의 밸런스를 맞춰서 다시 학습을 해보아야겠다.

![alt text]({{site.url}}/assets/img/balanced_dataset.png)

sample load하고 spilt하는 코드에 min_count로 가장 갯수가 적은 label에 대해서 1:1로 data balance를 맞출 수 있게 하였다.<br>
+optimizer를 adma에서 sgd 0.01 momentum 0.9 weight_decay=5e-4로 하고, 50step 마다 opt update하도록 수정 

📖 module.load_weights로 .npz load를 하고 unseen data에 대해서 적용해본 결과 거의 모든 경우에서 올바른 예측을 하였다.<br>
하지만, 해당 결과를 백트래킹해보니, wiener2 7x7 필터만 적용해도 Discriminator를 전부 속이는 것이 가능했다. + noise를 추가해도 안됨<br>
따라서 데이터를 조금 더 가공해서 다시 학습을 시켜야 겠다. 그리고 접근법을 여러가지의 chain으로 가져가는 것이 맞을 것 같다는 생각이든다.

<br>
### 📌 References
🧷 https://ml-explore.github.io/mlx-data/build/html/index.html<br>
🧷 https://ml-explore.github.io/mlx/build/html/index.html<br>
🧷 https://blog.jaeyoon.io/2017/12/jekyll-image.html<br>

<!-- --- -->
<!-- 
#### Contact
📞 **Phone** : +82 10-6654-9551 <br>
📧 **Email** : [kdhluck@naver.com](mailto:kdhluck@naver.com) -->